### **III.1 Description of the research area and the data sets used in the case study**
The workflow is presented on a case study area in Vorarlberg, Alps...

```{r Figure-3, echo=FALSE, fig.align='center', out.width="75%", out.height="75%", fig.cap="The case study area Vorarlberg (further ROI) with the four training areas"}
knitr::include_graphics('C:/Users/kelto/Documents/detectATE/analysis/paper/figures/Figure_5.png')
```

### **III.2 The reproducible workflow**

The reproducible workflow is contained in the files: **00_library_n_prep.R**, **0_set_up_working_envrnmt.R**, **1_data_prep_general.R**, **2_segmentation_area_1.R**, **3_segmentation_validation_ROI.R**, **4_data_prep_classification_area_1.R**, **5_classification_validation_area_1.R** and **6_data_prep_classification_ROI.R**.

These R files contain the whole selection process of the best suitable variables. This .Rmd only present the best suitable variables, with references to the respective .R files. 

To reproduce the results of the whole project you can do that by running the code in the .R files, numbered sequentially. 00_ is the library file, you do not have to run it. **0_set_up_working_envrnmnt.R** is going to set up the project folder structure on your computer/laptop by adapting the path of the project directory to your computer/laptop. Then you have to download the data from Google Drive in the respective folders (because a)**github** limits the size of data to be uploaded and b) the data used is not openly available, that is proprietary) and put the data into the respective folders of the folder structure you just created on your computer: **dsm/**, **dem/**, **RGB_IR/**, **RGB_IR/**, **treepos/**, **train/**.

The workflow consist of to main workflows: the pixel-based image classification and the Object Based Image Analysis which will be combined at the end. 
First the values of the variables to be used were elaborated/tested on test area 1 and then applied to the ROI. Thus you will first work with test area 1 and then apply the result on the ROI. Also only the successful result will be used in this .Rmd. You can learn about the testing sequence by checking it in the respective **.R** files.

Flowchart of the workflow

## **III.2.1 Data preparation (.R file: 1_data_prep_general.R)**

Originally masks for each 4 test area were created in QGIS and based on them, the CHM and the RGB and IR imagery was cropped to the size of the test area masks. When it was found that the minimal computable raster size (because of the restrictions of the 'raster' package) was a lot smaller than the maximum size of the actual ROI originally decided, the size of the ROI was reduced and the sizes of the test areas were defined by using the **'Clip raster by Extent'** tool, with ***'use map canvas'*** setting in QGIS, to 4 approximately 32 x 32 m test areas. Then the respective CHM test areas were used as masks/extents to clip the respective RGB and IR test areas in QGIS. 

After the folder structure on the computer/laptop was set up by executing the code in **0_set_up_working_envrnmnt.R**, the raw data will be prepared and the CHM for the ROI is generated by subtracting the DEM from the DSM! Following that the position and the properties of the CHM  just created are checked and the layer is renamed. Then the CHM is read in again and plotted to check it's crs.

``` {r create-chm, echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE}
library(sp)
library(raster)
library(mapview)

dem <- raster::raster(here::here('analysis/data/dem/DEM_ROI.tif'))
dsm <- raster::raster(here::here('analysis/data/dsm/DSM_ROI.tif'))
#create chm
chm <- dsm-dem 
#rename layer
names(chm) <-"chm_ROI"
#check crs 
crs(chm)
#plot raster
mapview(chm)
#write out the chm of the ROI####
writeRaster(chm, paste0(path_analysis_results_chm, "chm_ROI.tif"), 
            format="GTiff", overwrite=TRUE)
#read chm you just wrote out
chm <- raster::raster(here::here(path_analysis_results_chm, "chm_ROI.tif"))
#check crs
crs(chm)
plot(chm)
```

## **III.2.2 Segmentation of test area 1 (.R file: 2_segmentation_area_1.R)**

The aim of this step is to find an accurate segmentation for test area 1 which can be tested 
on the other areas and then applied to the ROI.

The first task is to set verification points, called tree positions for CHM_1. First of all the 
minimum height of a tree has to be decided (which of course is region and area dependent). In the Alpine region we also have shrubs and Krummholz, which has to be distinguished from trees. If one also would like to consider the young trees, then the highest point of the shrubs has to be determined and the height for the trees has to be set above the highest shrubs. If one would be concentrating on grown trees, still the CHM in QGIS has to be checked and the minimum height of a tree has to be decided on that basis and this cannot be modified. The best is if one classifies the CHM in QGIS based on the tree heights and check with the RGB/IR imagery where the shrubs 'finish' and the trees 'start'. 

Fist load CHM_1 and the corresponding tree positions and plot them together:

``` {r load-CHM1-vp1, echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE} 
library(sp)
library(raster)
library(mapview)

lschm <-list.files(file.path(path_analysis_results_chm), pattern=".tif")

#make the plot show more than the minimum of rows
options(max.print=10000)

#load the chms of test area 1
CHM_1 <- raster(here::here(path_analysis_results_chm, lschm[[1]]))
crs(CHM_1)

#load the verification points of test chm_1!
vp_1 <- rgdal::readOGR(here::here(path_analysis_data_treepos, "treepos_1.shp"))
#check the projection of vp_1 respective to chm_1:
crs(vp_1)
crs(chm_1)
#transform the projection of vp_1 to that of chm_1
vp_1 <- spTransform(vp_1, crs(chm_1))
crs(vp_1)

#plot chm_1 and vp_1
mapview(chm_1) + vp_1
```

Based on the classification of the CHM in QGIS it was decided for CHM_1, that 
h = 4 is a good height to get the lowest young trees but not to get involved 
with the shrubs and Krummholz. 

With the function **TreeSeg** it is possible to find the minimal and maximal values 
for *a*, *b* (horizontal and vertical values (x, y) in meters) and *h* (height in meters) based on the CHM (and vp - verification points/tree positions). This means it is possible to test various settings beforehand and then inspect the results in QGIS. Feeding long variable sequences to **BestSegVal** can make the calculation time long and if one wants to compare what the different settings of the different variables do, it is easier to test it without sequences.  
It can be tested if there is a need to use a *sum* filtered CHM (see the difference between **test_0** and **test_1**) or how big or small the variable *a*, *b* and *MIN* have to be set. Based on the fact that there are 15 trees in test area 1 we can estimate how accurate the segments might be. Taking a look at test 1, 2 & 3 we can see how the reduction of *a* and *b* elevated the number of trees. 

Thus we can move on to function of **BestSegVal**, which works with value sequences for all variables and takes also the tree positions (vp) in account. 
In the first run we test the following values: 
**a=seq(0.05, 0.1, 0.01), b=seq(0.05, 0.1, 0.01), h=seq(3.5, 6, 0.5), MIN=seq(0.1, 0.5, 0.1)**, to go a bit lover and above the actual height of the trees and to determine the best *a*, *b* and *MIN* values. *CHMfilter* is set at 3, because we want to do only minimal filtering to close the gaps. 
In the first run we got 1080 results and 44 maximal segments. Because there are 15 trees in test area 1, the tibble was filtered to 20 segments (a bit above our desired count) and arranged according to the best hitrate (which was 0.733333) and still gave 668 results. These are still too much to decide which combination of settings should be used on the other areas.
Thus the results were filtered to a **hitrate >= 0.7** and **height <= 4.0.** This resulted in 40 observations, from which the first 4 were actually calculated with *TreeSeg* and compared in QGIS. There was only minimal difference between **test_vp0** and **test_vp1**, based on the difference of 0.5 m height. It became clear that MIN (the size of the smallest segment) has to be set to 0.1.  

Thus in the second run the following variables were set to a fix value or respective to the same sequence: **MIN=0.1, h=seq(3.5, 6, 0.5)** and *a* and *b* were tested for a sequence between *0.01 and 0.1 with 0.01 steps*, to find better segment sizes. The second run (600 results) was filtered the same way (filtering to 20 segments lead to 204 results - the best hitrate being still 0.733333; the filtering to **hitrate >= 0.7** and **height <= 4.0**. lead to 8 observations) resulted in the same six results of **head(best_seg_vp_1_filt)** and two additional, so these 8 results will be inspected in the next step and only the second run will be displayed here. You can trace all steps in the respective .R files.

``` {r supervised segmentation chm1, echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE} 
library(sp)
library(raster)
library(mapview)
library(CENITH)
library(rgdal)
#make the plot show more than the minimum of rows
options(max.print=10000)

#load the chms of test area 1
chm_1 <- raster(paste0(path_chm, lschm[[1]]))
crs(chm_1)

#load the verification points of test chm_1!
vp_1 <- rgdal::readOGR(paste0(path_treepos, "treepos_1.shp"))
#check the projection of vp_1 respective to chm_1:
crs(vp_1)
crs(chm_1)
#transform the projection of vp_1 to that of chm_1
vp_1 <- spTransform(vp_1, crs(chm_1))
crs(vp_1)

#test settings for TreeSeg
#test_0 <- TreeSeg(chm_1, a=0.1, b=0.2, h=4.5, MIN=1)
#11 trees remaining
#writeOGR(obj=test_0, dsn="segm", layer="chm1_test_0", driver="ESRI Shapefile",
#         overwrite = TRUE)

#test_1 <- TreeSeg(chm_1, a=0.1, b=0.2, h=4.5, MIN=1, CHMfilter = 3)
#11 trees remaining
#writeOGR(obj=test_1, dsn="segm", layer="chm1_test_1", driver="ESRI Shapefile",
#         overwrite = TRUE)

#test_2 <- TreeSeg(chm_1, a=0.1, b=0.1, h=4.5, MIN=1, CHMfilter = 3)
#13 trees remaining
#writeOGR(obj=test_2, dsn="segm", layer="chm1_test_2", driver="ESRI Shapefile",
#         overwrite = TRUE)

#test_3 <- TreeSeg(chm_1, a=0.05, b=0.05, h=4.5, MIN=1, CHMfilter = 3)
#39 trees remaining
#writeOGR(obj=test_3, dsn="segm", layer="chm1_test_3", driver="ESRI Shapefile",
#         overwrite = TRUE)

#lines 289 to 317 are commented out if not the knitting takes ages
#best_seg_vp_1_v2 <-BestSegVal(chm=chm_1, a=seq(0.01, 0.1, 0.01), b=seq(0.01, 0.1, 0.01), 
#                              h=seq(3.5, 6, 0.5), MIN=0.1, filter=3, 
#                              vp=vp_1, skipCheck = TRUE)
#write.csv(best_seg_vp_1_v2, file.path(path_segm, "best_seg_vp_1_v2.csv"))
#best_seg_vp_1_v2 <- read.csv(file.path(path_segm, "best_seg_vp_1_v2.csv"), header = TRUE, sep=",")
#head(best_seg_vp_1_v2)

#let's transform the data table as a tibble####
#best_seg_vp_1_v2 <- as_tibble(best_seg_vp_1_v2)

#we have 15 trees/treepoints/vps, so let's filter the dataset to those results #
#which have 20 segments
#best_seg_vp_1_v2 <- best_seg_vp_1_v2 %>%
#  select(2:15)%>%
#  arrange(total_seg)%>%
#  filter(total_seg<=20)%>%
#  arrange(desc(hitrate))

#head(best_seg_vp_1_v2)

#we get only 668 and we can see that the best hitrate is 0.7333333, so let's 
#look for the highest hitrates, order it according to the most total segments 
#and filter for up to 4 m height
#best_seg_vp_1_v2_filt <- best_seg_vp_1_v2 %>% 
#  filter(hitrate >= 0.7)%>%
#  arrange(desc(total_seg))%>%
#  filter(height <= 4.0)

#best_seg_vp_1_v2_filt
# A tibble: 8 x 14
#      a     b height total_seg hit.vp  under  over  area hitrate underrate overrate Seg_qualy     MIN chm    
#  <dbl> <dbl>  <dbl>     <int> <chr>   <int> <int> <dbl>   <dbl>     <dbl>    <dbl> <chr>       <dbl> <chr>  
#1  0.07  0.07    3.5        20 11 / 15     2     7  538.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#2  0.07  0.08    3.5        20 11 / 15     2     7  538.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#3  0.07  0.09    3.5        20 11 / 15     2     7  538.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#4  0.07  0.07    4          20 11 / 15     2     7  530.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#5  0.07  0.08    4          20 11 / 15     2     7  530.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#6  0.07  0.09    4          20 11 / 15     2     7  530.   0.733     0.1      0.35  0.73 @ 0.28   0.1 CHM_1_3
#7  0.07  0.1     3.5        19 11 / 15     2     6  538.   0.733     0.105    0.316 0.73 @ 0.26   0.1 CHM_1_3
#8  0.07  0.1     4          19 11 / 15     2     6  530.   0.733     0.105    0.316 0.73 @ 0.26   0.1 CHM_1_3

```
##  **III.2.3 Cross-validation of test areas and Segmentation of ROI (.R file: 3_segmentation_validation_area_1_ROI.R)**

The segmentation of test area 1 resulted in 8 possible segmentations which are going to be tested if they fit the other test areas. Up to some degree it is a kind of guess work to test the possibly best segmentation which fits the other test areas and also fits the ROI. That is why all 8 results from **best_seg_vp_1_filt** were processed. The 8 results contain also results with h=3.5 m, so it can be checked which height can really represent the whole ROI. After the visual check in QGIS it became clear, that h=3.5 m is too low because it may result in segmenting some of the shrub too. Of course this depends on the definition of tree height and if one wants to segment also the seedlings. Because of the similar height of the seedlings and shrubs it is practically impossible to distinguish shrubs and seedlings based purely on height. 

While inspecting **segm_ROI -> segm_ROI_8** (demonstrating almost the same overall performance) it became clear that **segm_ROI_8** delivers the best result. But what happens with heights a bit above 4 m? 4.5, 5 and 5.1 m were tested to test if the segmentation can be even better than **segm_ROI_8**. We can see - as expected - that with the increase of the tree height less seedling and tree crown area is included. Thus the optimal result is **segm_ROI_8**.
You can see the results of **segm_ROI_9** to **segm_ROI_12** in the respective script. 

``` {r crossvalidation & segmentation of ROI, echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE}
library(sp)
library(raster)
library(mapview)
library(CENITH)
library(rgdal)

#make the plot show more than the minimum of rows
options(max.print=10000)

#check lschm
lschm
#[1] "chm_1.tif"         "chm_1.tif.aux.xml" "chm_2.tif"         "chm_2.tif.aux.xml" #"chm_3.tif"  "chm_3.tif.aux.xml" "chm_4.tif" "chm_4.tif.aux.xml" "chm_ROI.tif"  

                                  ####LOAD THE CHMS#### 
chm_1 <- raster(paste0(path_chm, lschm[[1]]))
crs(chm_1)
#+proj=tmerc +lat_0=0 +lon_0=10.3333333333333 +k=1 +x_0=0 +y_0=-5000000 +ellps=bessel +units=m +no_defs
chm_2 <- raster(paste0(path_chm, lschm[[3]]))
crs(chm_2)
chm_3 <- raster(paste0(path_chm, lschm[[5]]))
crs(chm_3)
chm_4 <- raster(paste0(path_chm, lschm[[7]]))
crs(chm_4)
CHM <- raster(paste0(path_chm, lschm[[9]]))
crs(CHM)

                        ####LOAD VERIFICATION POINTS####
#vp_1####
vp_1 <- rgdal::readOGR(paste0(path_treepos, "treepos_1.shp"))
crs(vp_1)
#+proj=tmerc +lat_0=0 +lon_0=10.3333333333333 +k=1 +x_0=0 +y_0=-5000000 +ellps=bessel +towgs84=577.326,90.129,463.919,5.137,1.474,5.297,2.4232
#+units=m +no_defs
crs(chm_1)
#transform the projection of vp_1
vp_1 <- spTransform(vp_1, crs(chm_1))
crs(vp_1)
#+proj=tmerc +lat_0=0 +lon_0=10.3333333333333 +k=1 +x_0=0 +y_0=-5000000 +ellps=bessel +units=m +no_defs

#vp_2####
vp_2 <- rgdal::readOGR(paste0(path_treepos, "treepos_2.shp"))
crs(vp_2)
crs(chm_2)
#transform the projection of vp_1
vp_2 <- spTransform(vp_2, crs(chm_1))
crs(vp_2)

#vp_3####
vp_3 <- rgdal::readOGR(paste0(path_treepos, "treepos_3.shp"))
crs(vp_3)
crs(chm_3)
#transform the projection of vp_1
vp_3 <- spTransform(vp_3, crs(chm_1))
crs(vp_3)

#vp_4####
vp_4 <- rgdal::readOGR(paste0(path_treepos, "treepos_4.shp"))
crs(vp_4)
crs(chm_4)
#transform the projection of vp_1
vp_4 <- spTransform(vp_4, crs(chm_1))
crs(vp_4)

                               ####LOAD LISTS####
chmlist <- list(chm_1, chm_2, chm_3, chm_4)
vplist <- list(vp_1, vp_2, vp_3, vp_4)

                      ####CV ON THE TEST AREAS####

cv8 <- CENITH::TreeSegCV(sites=chmlist, a=0.07, b=0.1, h=4, MIN=0.1, MAX=1000, CHMfilter=3, vps=vplist)
#Overall perfomance of model: 0.78 @ 0.31

                  ####SEGMENT THE WHOLE ROI####
segm_ROI_8 <- CENITH::TreeSeg(CHM, a=0.07, b=0.1, h=4, MIN = 0.1, CHM=3)
#detected 847 trees
#clipped: 61 polygons. 786 trees remaining
writeOGR(obj=segm_ROI_8, dsn="segm", layer="segm_ROI_8", driver="ESRI Shapefile")
```
##  **III.2.4 Data preparation for the Classification (.R file: 4_data_prep_classification:area_1.R)**

For the preparation for the spectral classification first we will compute RGB and then multi-spectral (MS) indices, which we will filter and then test on correlation. Then 10 predictor sets are built which will be tested in the next step. 
The indices are used to enhance the spectral differences between the different object classes which are to be detected. Currently 11 RGB and 4 MS indices are implemented.
Additionally the filter enhance special properties of indices and the overall homogeneity of spectral areas and enhance the edges and between the different objects. During the testing it was understood, that there are certain indices which contain too homogeneous areas from the beginning thus filtering them would distort the values and they would not be kicked out by the correlation and would deform the prediction. 
Thus three different index stacks were complied: 
*RGB_1_ind (VVI, VARI, NDTI, RI, CI, BI,SI,HI, TGI, GLI, NGRDI)*
*RGB_1_ind2 (VVI, NDTI, CI, BI, SI, TGI, GLI, NGRDI)*
Which were then stack together to form the following data stacks: 
*ALL_1_stack (RGB_1_ind, RGBNIR_1_ind)* 15 layer
*ALL_1_stack2 (RGB_1_ind2, RGBNIR_1_ind)* 12 layer
*ALL_1_stack3 (RGB_1_ind, RGBNIR_1_ind, RGBNIR_1)* had been corrected by subtracting HI: 18 layer
Different data stacks were tested to see if more data would filter out/overlay the shortcomings of certain indices. The homogeneity test filtered out the homogeneous indices, that is also VARI and RI, but HI had to be extracted separately.

![Figure 6. Plot of ALL_1stack3 with 16 of the layers (Green, Blue and NIR are missing). Note the indices VVI, VARI, RI HI and also SI. The homogeneous regions cause problems when using spectral information for classification. Thus these must be eliminated form the dataset used for the classification - either by the detection of raster homogeneity or by previously eliminating the anomlalous indices.](/home/keltoskytoi/ATE_detection/images_Rmd/Figure_6.png)


``` {r dataprep & classification area 1_1, echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE}
library(sp)
library(raster)
library(LEGION)
library(rgdal)

lsRGBIR <- list.files(file.path(path_RGB_IR), pattern=".tif")
lspredictor1 <- list.files(file.path(path_prdctr1), pattern=".tif")
lspredictor2 <- list.files(file.path(path_prdctr2), pattern=".tif")
lspredictor3 <- list.files(file.path(path_prdctr3), pattern=".tif")
lspredictor4 <- list.files(file.path(path_prdctr4), pattern=".tif")
lspredictor5 <- list.files(file.path(path_prdctr5), pattern=".tif")
lspredictor6 <- list.files(file.path(path_prdctr6), pattern=".tif")
lspredictor7 <- list.files(file.path(path_prdctr7), pattern=".tif")
lspredictor8 <- list.files(file.path(path_prdctr8), pattern=".tif")
lspredictor10 <- list.files(file.path(path_prdctr10), pattern=".tif")

#check the order of the raster files
lsRGBIR

#RGB of area 1####
RGB_1 <- raster::stack(paste0(path_RGB_IR, lsRGBIR[[10]]))
crs(RGB_1)
#+proj=tmerc +lat_0=0 +lon_0=10.3333333333333 +k=1 +x_0=0 +y_0=-5000000 +ellps=bessel +units=m
#+no_defs
#check the names and the band order!
names(RGB_1)
#"Red"   "Green" "Blue" 

#IR of area 1####
IR_1  <-  raster(paste0(path_RGB_IR, lsRGBIR[[1]])) 
crs(IR_1)
# +proj=tmerc +lat_0=0 +lon_0=10.3333333333333 +k=1 +x_0=0 +y_0=-5000000 +ellps=bessel +units=m
#+no_defs 
names(IR_1)
#"IR_1"

#stack RGB & IR of area 1####
RGBNIR_1 <- raster::stack(RGB_1, IR_1)
names(RGBNIR_1)
#"Red"   "Green" "Blue"  "IR_1" 

#################################COMPUTE INDICES###############################
##Compute RGB indices -11 layer ####
RGB_1_ind <- LEGION::vegInd_RGB(RGB_1, 1,2,3, indlist="all")
names(RGB_1_ind)
#[1] "VVI"   "VARI"  "NDTI"  "RI"    "CI"    "BI"    "SI"    "HI"    "TGI"   "GLI"   "NGRDI"

#it was understood from testing, that VARI, HI, RI contain too homogeneous areas, which distort the prediction - 8 layer
vi <-c("VVI","NDTI", "CI", "BI", "SI","TGI", "GLI", "NGRDI")
RGB_1_ind2 <- LEGION::vegInd_RGB(RGB_1, 1,2,3, indlist=vi)
names(RGB_1_ind2) 
#[1] "VVI"   "NDTI"  "CI"    "BI"    "SI"    "TGI"   "GLI"   "NGRDI"

#Compute RGBNIR indices - 4 layer####
RGBNIR_1_ind <- LEGION::vegInd_mspec(RGBNIR_1, 1,2,3,4, indlist="all")
names(RGBNIR_1_ind)
#[1] "NDVI" "TDVI" "SR" "MSR" 

                    ####MERGE RASTER STACKS#####
ALL_1_stack <- raster::stack(RGB_1_ind, RGBNIR_1_ind) # 15 layer
names(ALL_1_stack)
#[1] "VVI"   "VARI"  "NDTI"  "RI"    "CI"    "BI"    "SI"    "HI"    "TGI"   
#"GLI"   "NGRDI" "NDVI" "TDVI"  "SR"    "MSR

#without VARI, HI, RI - 12 layer
ALL_1_stack2 <- raster::stack(RGB_1_ind2, RGBNIR_1_ind)
names(ALL_1_stack2)
#[1] "VVI"   "NDTI"  "CI"    "BI"    "SI"    "TGI"   "GLI"   "NGRDI" "NDVI"  
#"TDVI"  "SR"    "MSR"

#RGB indices + Spectral indices + RGB + NIR - 19 layer
ALL_1_stack3 <- raster::stack(RGB_1_ind, RGBNIR_1_ind, RGBNIR_1)
names(ALL_1_stack3)
```

