# Methodology

## **Description of the research area and the data sets used in the case study**
The workflow is presented on a case study area in the Vorarlberg, Alps...

## **The reproducible workflow**

The reproducible workflow is made up of the files: **00_library_n_prep.R**, **0_set_up_working_envrnmt.R**, **1_data_prep_general.R**, **2_segmentation_test_area_1.R**, **3_segmentation_validation_ROI.R**, **4_data_prep_classification_test_area_1.R**, **5_classification_validation_test_area_1.R** and **6_data_prep_classification_ROI.R**, **7_classification_ROI.R**.

These commented R files build up on each other step-by-step, starting with the preprocessing of the input data. This .Rmd only presents the backbone which links the .R files together. 

To reproduce the results of the whole project you have to run the code in the .R files, numbered sequentially. **00_library_n_prep.R** is a library file, containing all the packages needed for this project. It installs packages from the R repository or from github if some would be missing. This file does not need running, unlike the next one, **0_set_up_working_envrnmnt.R**. It is going to set up the project folder structure on your computer/laptop, but you have to adapt the path of the project directory to the destined place on your computer/laptop and also attach or install the packages needed. 
The data used in this project is stored on Google Drive, from where you have to download it to the respective folders (**dsm/**, **dem/**, **RGB_IR/**, **RGB_IR/**, **treepos/**, **train/**) set up on you device by the script you just ran (because a)**github** limits the size of data to be uploaded and b) the data used is not openly available, that is proprietary).

The main workflow consist of to sub-workflows, which are equally important: the Object Based Image Analysis (**.R files 2-3**, working with the LiDAR data set) and the Pixel-Based Image Classification (**.R files 4-5-6-7**, working with the Satellite data set), which will be combined at the end (**.R file 8**). 

Flowchart of the workflow

The .R files are commented in a manner, that they can be used as a manual or tutorial. In this chapter only the ideas behind the workflow and in the next chapter the results will be discussed to keep it short.

For this project three R packages were developed: *LEGION*, *CENITH* and *IKARUS*. 
**LEGION** computes indices from RGB and Multispectral Imagery and provides also their basic statistics (correlation and homogeneity). See more details in the help pages and in the tutorial of the package. 
**CENITH** is a wrapper for the *ForestTools package* (Plowright and Roussel 2020) to perform tree segmentation on a specific area. It also provides cross validation to estimate and validate the performance of a segmentation model for multiple test areas. See more details in the help pages and in the tutorial of the package.  
**IKARUS** is a wrapper for the *CAST* package (Meyer 2020) to perform Pixel-based Image Analysis and classification.See more details in the help pages and in the tutorial of the package.

## **General data preparation (.R file: 1_data_prep_general.R)**

For the project a Region of Interest (later ROI) was chosen which displays the different vegetation types at this specific ATE. Four test areas were defined within the ROI. The workflow is designed in such a way, that the individual steps of the workflow were developed on test area 1 and tested (generalized) on the other (test) areas to deal with the unavoidable variability of data. The resulting settings and variables are then to applied to the ROI. This three-step procedure is used to make sure that the algorithms applied and values used are effective and robust. 

Originally masks for each 4 test areas were created in QGIS and based on them, the Canopy Height Model (CHM) and the RGB and IR (Infra-Red) imagery was cropped to the size of the test area masks. When it became clear, that the minimal computable raster size (on grounds of the restrictions of the 'raster' package in R) was a lot smaller than the maximum size of the actual ROI originally decided, it was reduced. The sizes of the CHM test areas were defined using the **'Clip raster by Extent'** tool, with the ***'use map canvas'*** setting in QGIS, to define 4, approximately 32 x 32 m test areas. Then the respective CHM test areas were used as masks/extents to clip the respective RGB and IR test areas in QGIS. 

The CHM was created by subtracting the Digital Elevation Model (DEM) form the Digital Surface Model (DSM). This way only the LiDAR points connected to the vegetation above ground are preserved and can be used for our calculations.

## **Segmentation of test area 1 (.R file: 2_segmentation_test_area_1.R)**

The aim of this step is to find an accurate segmentation for test area 1 which can be tested on the other test areas and then applied to the ROI.

The segmentation is performed using the CENITH package. As CENITH is a wrapper for ForestTools, it also uses the **Watershed Segmentation** using markers (Meyer and Beucher 1990) which is implemented in ForestTools. 

The first task is to set verification points (this can be also done with the ForestTools package, but we preferred to do it by hand so it was not implemented in the CENITH package), called tree positions for chm_1. 
For this first of all the minimum height of a tree has to be decided (which of course is region and area dependent). In the Alpine region we also have shrubs and Krummholz, which has to be distinguished from trees. If one also would like to consider the young trees, then the highest point of the shrubs has to be determined and the height for the trees has to be set above the highest shrubs. If one would be concentrating on grown trees, still the CHM in QGIS has to be checked and the minimum height of a tree has to be decided on that basis and this cannot be modified. The best is if one classifies the CHM in QGIS based on the tree heights and check with the RGB/IR imagery where the shrubs 'finish' and the trees 'start'. 

Fist load CHM_1 and the corresponding tree positions and plot them together:

Based on the classification of the CHM in QGIS it was decided for CHM_1, that 
h = 4 is a good height to get the lowest young trees but not to get involved 
with the shrubs and Krummholz. 

With the function **TreeSeg** it is possible to find the minimal and maximal values 
for *a*, *b* (horizontal and vertical values (x, y) in meters) and *h* (height in meters) based on the CHM (and vp - verification points/tree positions). This means it is possible to test various settings beforehand and then inspect the results in QGIS. Feeding long variable sequences to **BestSegVal** can make the calculation time long and if one wants to compare what the different settings of the different variables do, it is easier to test it without sequences.  
It can be tested if there is a need to use a *sum* filtered CHM (see the difference between **test_0** and **test_1**) or how big or small the variable *a*, *b* and *MIN* have to be set. Based on the fact that there are 15 trees in test area 1 we can estimate how accurate the segments might be. Taking a look at test 1, 2 & 3 we can see how the reduction of *a* and *b* elevated the number of trees. 

Thus we can move on to function of **BestSegVal**, which works with value sequences for all variables and takes also the tree positions (vp) in account. 
In the first run we test the following values: 
**a=seq(0.05, 0.1, 0.01), b=seq(0.05, 0.1, 0.01), h=seq(3.5, 6, 0.5), MIN=seq(0.1, 0.5, 0.1)**, to go a bit lover and above the actual height of the trees and to determine the best *a*, *b* and *MIN* values. *CHMfilter* is set at 3, because we want to do only minimal filtering to close the gaps. 
In the first run we got 1080 results and 44 maximal segments. Because there are 15 trees in test area 1, the tibble was filtered to 20 segments (a bit above our desired count) and arranged according to the best hitrate (which was 0.733333) and still gave 668 results. These are still too much to decide which combination of settings should be used on the other areas.
Thus the results were filtered to a **hitrate >= 0.7** and **height <= 4.0.** This resulted in 40 observations, from which the first 4 were actually calculated with *TreeSeg* and compared in QGIS. There was only minimal difference between **test_vp0** and **test_vp1**, based on the difference of 0.5 m height. It became clear that MIN (the size of the smallest segment) has to be set to 0.1.  

Thus in the second run the following variables were set to a fix value or respective to the same sequence: **MIN=0.1, h=seq(3.5, 6, 0.5)** and *a* and *b* were tested for a sequence between *0.01 and 0.1 with 0.01 steps*, to find better segment sizes. The second run (600 results) was filtered the same way (filtering to 20 segments lead to 204 results - the best hitrate being still 0.733333; the filtering to **hitrate >= 0.7** and **height <= 4.0**. lead to 8 observations) resulted in the same six results of **head(best_seg_vp_1_filt)** and two additional, so these 8 results will be inspected in the next step and only the second run will be displayed here. You can trace all steps in the respective .R files.

## **Cross-validation of test areas and Segmentation of ROI (.R file: 3_segmentation_validation_area_1_ROI.R)**

The segmentation of test area 1 resulted in 8 possible segmentations which are going to be tested if they fit the other test areas. Up to some degree it is a kind of guess work to test the possibly best segmentation which fits the other test areas and also fits the ROI. That is why all 8 results from **best_seg_vp_1_filt** were processed. The 8 results contain also results with h=3.5 m, so it can be checked which height can really represent the whole ROI. After the visual check in QGIS it became clear, that h=3.5 m is too low because it may result in segmenting some of the shrub too. Of course this depends on the definition of tree height and if one wants to segment also the seedlings. Because of the similar height of the seedlings and shrubs it is practically impossible to distinguish shrubs and seedlings based purely on height. 

While inspecting **segm_ROI -> segm_ROI_8** (demonstrating almost the same overall performance) it became clear that **segm_ROI_8** delivers the best result. But what happens with heights a bit above 4 m? 4.5, 5 and 5.1 m were tested to test if the segmentation can be even better than **segm_ROI_8**. We can see - as expected - that with the increase of the tree height less seedling and tree crown area is included. Thus the optimal result is **segm_ROI_8**.
You can see the results of **segm_ROI_9** to **segm_ROI_12** in the respective script. 

##  **Data preparation for the Classification (.R file: 4_data_prep_classification:area_1.R)**

For the preparation for the spectral classification first we will compute RGB and then multi-spectral (MS) indices, which we will filter and then test on correlation. Then 10 predictor sets are built which will be tested in the next step. 
The indices are used to enhance the spectral differences between the different object classes which are to be detected. Currently 11 RGB and 4 MS indices are implemented.
Additionally the filter enhance special properties of indices and the overall homogeneity of spectral areas and enhance the edges and between the different objects. During the testing it was understood, that there are certain indices which contain too homogeneous areas from the beginning thus filtering them would distort the values and they would not be kicked out by the correlation and would deform the prediction. 
Thus three different index stacks were complied: 
*RGB_1_ind (VVI, VARI, NDTI, RI, CI, BI,SI,HI, TGI, GLI, NGRDI)*
*RGB_1_ind2 (VVI, NDTI, CI, BI, SI, TGI, GLI, NGRDI)*
Which were then stack together to form the following data stacks: 
*ALL_1_stack (RGB_1_ind, RGBNIR_1_ind)* 15 layer
*ALL_1_stack2 (RGB_1_ind2, RGBNIR_1_ind)* 12 layer
*ALL_1_stack3 (RGB_1_ind, RGBNIR_1_ind, RGBNIR_1)* had been corrected by subtracting HI: 18 layer
Different data stacks were tested to see if more data would filter out/overlay the shortcomings of certain indices. The homogeneity test filtered out the homogeneous indices, that is also VARI and RI, but HI had to be extracted separately.
