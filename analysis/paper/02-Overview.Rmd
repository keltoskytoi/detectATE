# **Overview of Alpine Treeline Ecotone Research with focus on methodology**

Alpine Treeline Ecotone analysis has been carried out so far at local, regional and global scales with different focus. @chhetriRemoteSensingGeographic2019 investigate the use of GIS and remote sensing methods in ATE research between 1980 and 2017 and demonstrate that with the advances in sensor technology the access to higher resolution data and different data types the analysis methods diversify. The idea of a research overview to underline the reasons for this project is based on and was inspired by @chhetriRemoteSensingGeographic2019, with the focus on the automated detection of ATEs. The following crude overview groups ATE research based on different remote sensing approaches and is by no means comprehensive. In many cases it is hard to distinguish between the different methodological approaches because they all applied multiple methods and methods have been applied for diverse scopes. 

## **Statistical – analytical approach** 

Until the dispersal of openly available remote sensing products the approach to ATEs was mainly concentrated on physiological response based investigations with statistical analysis of local indicators based on *in situ* measurements. The main question was: which environmental drivers control the location of ATE’s and how complex are these (@kornerReassessmentHighElevation1998)? Drivers were differentiated on global, regional and local levels (@holtmeierSensitivityResponseNorthern2005). Temperature was defined as the main global driver (@kornerReassessmentHighElevation1998,  @koernerWasSteuertPflanzenwachstum2012, @holtmeierTreelineAdvanceDriving2007, 2, @bonanomiAnthropogenicEnvironmentalFactors2018), but on regional and local levels it looks more diverse: topography (@brownPredictingVegetationTypes1994a, @virtanenModelingLocationForest2004 and @baderTopographybasedModelForest2008), geomorphologic processes, herbivory or anthropogenic disturbance (@chhetriRemoteSensingGeographic2019) were identified as drivers. Analysis of topographic actors with logistic regression was used frequently (e.g @brownPredictingVegetationTypes1994a, @virtanenModelingLocationForest2004 and @baderTopographybasedModelForest2008).

## **Remote sensing approach**

The detection or localization of ATEs is facilitated by the availability of remote sensing data (Satellite, Aerial and lately Hyperspectral and UAV derived Imagery). Specialized sensors operating in the R, G, B, IR, short-wave, Hyperspectral and Thermal regions of the electromagnetic spectrum give the possibility to approach and work with the specific spectral signatures (due to different absorption and reflection of radiation) of different vegetation entities. LiDAR data enables to include the factor height, thus moving the analysis of treelines in a 3D space. The main focus of this methodological project paper is on the remote sensing approach (especially automated detection) and exemplary papers (nowhere conclusive) are accentuated in a short summary. 
The use of GIS and remote sensing has been constantly increasing in treeline studies since 2000, with a few preceeding pioneers. Earlier studies concentrated on mapping treeline positions and lately the interest shifted towards factors that control treeline variation (@chhetriRemoteSensingGeographic2019, 1543). It can also be seen that with the development of the respective sensors the interest and use moved to data with higher spatial resolution (e.g. LiDAR and Hyperspectral data), which on the other hand attracts more cost and thus often thins out the studies due to the lack of monetary resources and also the need to use proprietary software. This shows that there is a lot to do in means of open-source and reproducible best-practice applications and code accessibility. 
The use of remotely sensed data is usually combined with classical approaches like statistical analysis in complex research questions, from which the following main directions emerge: 

### **Mapping of Alpine Treelines**

To map ATEs, studies use Aerial and Landsat Imagery to identify and quantify treelines (@brownPredictingVegetationTypes1994a, @bakerUsingAerialPhotography1995, @allenSpatialCompositionalPattern1996, @kimballAlpineVegetationCommunities2000, @virtanenModelingLocationForest2004, and @reslerMappingAlpineTreeline2004). Frequently also vegetation indices are used (@myneniIncreasedPlantGrowth1997, @singhRemoteSensingAlpine2015, and @mohapatraRemoteSensingAlpine2019) to analyse treeline elevation (@allenSpatialCompositionalPattern1996 and @kimballAlpineVegetationCommunities2000) and topographic variables/geomorphological parameters (slope, angle, curvature, relief) to explain treeline structure (patch-metrics) (@kimballAlpineVegetationCommunities2000). Tree population parameters are derived via PCA (e.g @bakerUsingGISModel1997) and also species distribution modelling is commonly applied (@chhetriTopographyHumanDisturbances2017).

### **Montitoring Alpine Treelines and their Change detection**

ATEs are space and time related phenomenons and they respond to changing environmental conditions, that is they can be sensitive to climate change (@singhRemoteSensingAlpine2015, @holtmeierSensitivityResponseNorthern2005, @holtmeierTreelineAdvanceDriving2007, @harschTreelineFormPotential2011, and @baderGlobalFrameworkLinking2021). The rise in global average temperatures seems to lead to the geographically varying shift of Ecotones: on regional level to upward shift (@mohapatraRemoteSensingAlpine2019) but also stable or retracting ATEs can be determined (@winingsMappingAlpineTreeline2013). It still has to be understood if the results are due data quality. The identification and quantification of change in the ATEs were carried out with regional and global monitoring (@chhetriRemoteSensingGeographic2019). 

### **Automated detection and mapping of Alpine Treelines and ATEs**

Recently several research projects, Master theses and PhDs have investigated (semi-)automated detection and mapping methods of Alpine Treelines (see a list until 2013 in @winingsMappingAlpineTreeline2013 and also recent literature cited here). As already stressed, the availability of high resolution data facilitates the use of more and more sophisticated methods. This methodological paper is concentrating specifically on automated analysis methods.  
Automated methods imply the use of specific algorithms to extract information from remote sensing data, either ***Pixel- or Object Based*** or recently also using ***Deep Learning*** (mainly *Convolutional Neural Networks - CNNs*). Some studies compare ***Object- and Pixel-based*** or different ***Object-based Segmentation methods*** (@immitzerTreeSpeciesClassification2012, @winingsMappingAlpineTreeline2013, and @kupkovaClassificationTundraVegetation2017). Further it has to be emphasized, that the automated detection of ATEs relies heavily on tree detection. Parallel to elaborated workflows for the automated detection of Alpine Treelines and Ecotones continuous improvements are made on tree detection methods and tree cover estimation (@whitesideSemiautomatedApproachQuantitative2020) closely connected to the development of sensors and new data processing methods (@qiuNewIndividualTree2020, @weinsteinIndividualTreeCrownDetection2019 and @weinsteinCrosssiteLearningDeep2020). In the following the most prominent automated methods are presented shortly including a few case studies.

***Pixel-based Image Analysis*** is working with the information encoded in pixels – it assigns each pixel to a specific class on the basis of the respective values of the spectral bands, index or morphometric information (slope, aspect, etc.). One drawback is, that the context of the pixels and its neighborhood gets neglected and the pixel values can be affected by circumstantial effects, like reflectance differences (@stueveSpatialVariabilityBiotic2011), shadow or clouds (@allenSpatialCompositionalPattern1996). Also the method doesn't deal with textures *per se*, and for this a textural analysis has to be done by using different filters (*mean*, *sobel*, *focal*, etc.). 

**@reslerMappingAlpineTreeline2004** use Panchromatic Aerial Imagery where they incorporate spectral (brightness values) and spatial (textural) information to classify 4 classes (tundra/bare, alpine meadow, open forest/krummholz and closed canopy) representing the ATE using the maximum likelihood algorithm. A classification with and without textural information was done to assess the meaningfulness of textural information. The ERDAS modeler was used to extract textures.  

**@kralClassificationCurrentVegetation2009** uses CIR Orthophotos to do a “classical” land cover classification using the *'Maximum Likelihood Classifier'*. THe result is reclassified into 2 classes (spruce canopies and other). Subsequently a *focal filter* is applied to the spruce canopy closure class for texture analysis, which is then reclassified into 5 classes (no trees, emergent trees, groups of trees, open-canopy forest, closed canopy forest). Class 3, that is groups of trees (26-50% spruce) neighboring alpine grassland and open-canopy forest was defined as ATE.

**@immitzerTreeSpeciesClassification2012** used WW2 Satellite data (8 + 4 bands) for the identification of 10 tree species by means of *'Random Forest Classification'*  using spectra of a) manually delineated tree crowns b) derived tree crown polygons and reference samples for tree species (**Object-based vs. Pixel-based Classification**).

**@winingsMappingAlpineTreeline2013** used high resolution Aerial Imagery and LiDAR data in her Masters thesis to map the Alpine Treeline. She compared **Pixel- and Object based Classification**. She used four different data input for both classification methods: NDVI, NDVI + Multispectral Aerial Imagery, NDVI + tree height or NDVI +  Multispectral Aerial Imagery + tree height. In the case of the **Pixel-based Classification** the *'Maximum Likelihood'* and the *'Unsupervised ISODATA (Iterative Self-Organizing Data Analysis Technique) Clustering'* algorithms were compared. For the **Object-based Image Analysis** *'Multiresolution Segmentation'* was conducted, based on color and shape homogeneity. After Segmentation the classes (tree vs. non-tree) were assigned based on object feature threshold. The accuracy for the **Pixel-based Classifications** was between 85.3 and 88.4 and for the **Object-based Image Analysis** between 81.5 and 92.9 %, resulting in the best classification on the data set with NDVI + Multispectral Aerial Imagery + tree height. For the **Pixel-based Image Analysis** ENVI and ERDAS and for the **Object-based Image Analysis** eCognition was used.

**@kupkovaClassificationTundraVegetation2017** used  Airborne Hyperspectral (APEX and AISA DUAL) and Sentinel-A data for the Classification of Tundra vegetation by comparing **Pixel-based and Object-based Image Analysis**. Reference data was collected corresponding to 8 vegetation classes (anthropogenic areas, picea abies, pinus mugo dense, pinus mugo sparse, closed alpine grassland, grasses, alpine heathlands, wetlands and peat bogs; with a detailed and a simplified legend). Based on the difference in resolution the Hyperspectral data and the Satellite Imagery was classified separately. Latter was only classified with *'Support Vector Machines with radial basis function (SVM)'*, *'Neural Net (NN)'* and *'Maximum Likelihood Classification (MLC)'* algorithms. The Hyperspectral data, having a higher spatial resolution was classified **Pixel- and Object-based**. For the **Pixel-based Classification** *'SVM, NN and MLC'* algorithms were used. For the **Object-based Image Analysis** *'Edge-based Segmentation'* was used on the Hyperspectral data sets. The Hyperspectral data yielded better classification result than the Satellite data, with *'SVM'* **Pixel-based classification**. ENVI was used for the study.

***Object-based Image Analysis (GeOBIA)*** on the other hand is dealing with the grouping of pixels in homogeneous groups, that is segments which bear similar spectral, spatial and textural information. From each segment additional information can be extracted (statistical information, size, shape and context).  Different Segmentation algorithms exist, which treat the image and the segments different. 

**@middletonObjectBasedChange2008** used the Feature Extraction Module (Fx) implemented in ENVI to extract tree crowns from two aerial photographs (one from 1947 and one from 2003) via Segmentation and Feature Classification with *'SVM'* with textural, spatial and spectral information. The results were compared to forest inventory information and an upward shift was recorded on Lommoltunturi fell. 

**@ransonObjectbasedMappingCircumpolar2011** used MODIS VCF (Vegetation Continuous Fields) tree cover data and segmentation to delineate the circumpolar Taiga-Tundra ecotone (TTE). The multi-annual VCF was adjusted using linear regressions and a vector layer with previously delineated Taiga and Tundra Biomes. Water bodies were masked out. Subsequently *'Multiresolution Segmentation'* was carried out with eCongnition based on the homogeneity criterion. The resulting polygons were then classified on a specific range of adjusted VCF values which represent the TTE.  

**@mishraSpeciesLevelVegetationMapping2018** used a UAV equipped with a Parrot Sequoia multispectral (Red, Green, Blue, Red Edge, Near Infra-Red) camera to acquire High Resolution Imagery. Subsequently an SfM Orthoimage was calculated and then *'Multiresolution'* (based on the homogeneity criterion of scale, shape/color and compactness/smoothness) and *'Spectral Difference Segmentation'* (merging neighboring objects based on a spectral threshold) was combined in eCognition to generate optimal feature space variables for the classes. Then the *'Random Forest Classifier'* was used for classification with 3 sets of features (spectral features; spectral features + geometric/shape features; spectral features + geometric/shape features + textural features) for species-level mapping of vegetation in the Himalayas.

**@whitesideSemiautomatedApproachQuantitative2020** used derivatives of Aerial Imagery and WW2 satellite data (TGI, NDVI) resampled to 1 m and filtered by a *'low-pass filter'*. Then a threshold-based *'Multiresolution Segmentation'* was conducted with eCognition to assess the tree cover (in percentage) for each date (1964, 1976, 1981, 2010). The results were compared by date to assess the tree cover reduction (4%) during the 36 years.

**@gepingluoDetectionAlpineTree2013** used Aerial Imagery from 1962 and 1981 and a QuickBird Satellite image from 2006 as data input to map vegetation distribution after Orthorectification and a DEM was generated. The land-cover types Schrenkiana, Sabina and other were delineated. *'Multiresolution Segmentation'* was conducted in eCognition subsequently combined with a *'k-Nearest Neighbour Classification'*. The result was compared to fieldwork data collection (2010, 2011) of the two species. Land-cover change was examined between 1962, 1981 and 2006.

**@qiuNewIndividualTree2020** proposed a new *'Spectral Multiscale (SMS) Individual Tree Crown (ITC) delineation'* method using both brightness and spectra of High-Resolution Multrispectral Imagery to be able to better delineate tree crowns in deciduous or mixed forests, where adjacent tree crowns are very close to each other. As the first step a *'Morphological Gradient Map'* is calculated of Multispectral images, then as a second step an *'Inverse Gradient Image'*. Then initial treetops were extracted by multiscale filtering and morphological operations with regard to tree crown shape which then were refined with the spectral reference of the neighboring tree crowns (creating a treetops map). Subsequently the *'Morphological Gradient Map'* is segmented by *'marker-controlled Watershed Segmentation'* which is then refined by the treetops map, to receive an individual tree crown delineation map. 

***Deep Learning*** – contrary to **Pixel-based Classification and Object-based Image Analysis** – works on scene level and enables thus to deal better with the complex semantic structure of the increasing resolution of remote sensing images. A multitude of different ***Deep Learning*** models exist with different structures to fulfill different aims (e. g. *Image Classification,*  *Object Segmentation*, e.g.). The most common ***Deep Learning*** model structure are *'CNNs – Convolutional Neural Networks'*: multilayer networks with learning ability that consist of convolutional layers, pooling layers, and fully connected layers.  

**@frickerConvolutionalNeuralNetwork2019** used airborne Hyperspectral Imagery, LiDAR data with a CNN Framework to automate tree species classification. 7 dominant tree species and a dead tree class were identified to serve as reference data for the *CNN*. A LiDAR derived **CHM** was used to digitize the individual tree canopies to prepare their pixels for the species labeling for the *CNN*. The classification was executed separately on the RGB and the hyper-spectral data. The classification with the hyper-spectral data (0.73 – 0.90) yielded better classification results than the RGB classification (0.41 – 0.88). All code and data to ensure reproducibility can be found online. 

**@weinsteinIndividualTreeCrownDetection2019** proposed a *Semi-Supervised CNN* workflow based on the comparison of 3 unsupervised *'Tree-Crown Segmentation algorithms'*. The result of the chosen *'Tree Crown Segmentation'* (clustering of a CHM by tree height and crown width) of the LiDAR data was extracted as a bounding box from the RGB image, which' data set is then labeled self-supervised and pretrained by a *'retinaNet CNN'*. The CNN was then retrained with a small hand-annotated data set (supervised classification), to correct errors from the initial *'Unsupervised Segmentation'*, which indeed improved the results of the prediction. 

**@weinsteinCrosssiteLearningDeep2020** build on the results from **@weinsteinIndividualTreeCrownDetection2019** and tested if training data sets can be generalized and be used on completely different forested areas. Generally the performance of the model performance decreased, but when they were applied to spatially and spectrally similar forested areas the performance increased. Best was again, when the *'CNN'* was retrained by a handful of hand-annotated data from the same area.

This overview of chosen literature demonstrated, that often it is not communicated which software was used and also no clear workflow, only a flowchart is published. The lack of good and clear workflow makes it difficult to understand studies in depth and to build upon them. The software used - if mentioned - is often proprietary (such as *ENVI* and *eCognition*), what means, that the results cannot be reproduced and even applied to and tested on different data sets. Only one of the investigated works are reproducible and replicable: @frickerConvolutionalNeuralNetwork2019. 

Inspired by this literature overview and based on the fact, that the automated detection of ATEs relies heavily on tree detection, a reproducible and replicable workflow is proposed to detect trees using so-called *'shallow learning'*, that is **Object-based Image Analysis (OBIA)** in case of available LiDAR data (which is sadly mostly not the case) and **Pixel-based Image Analysis (PBIA)** in the case of Aerial Imagery or Satellite data (which is usually the case). If both data sets are available, then the results of the **PBIA** can be compared with the result of the **OBIA** based on cell-statistics, bearing in mind the difference of both methods. The detection of trees is a robust information base for future analysis of ATEs. The workflow is described and explained in **Chapter 3 - Methodology**. The development of a **Deep Learning Architecture** (even using *Transfer Learning*) would've exceeded the scope and possibilities of a methodological project paper. 

During the development of the workflow the following points were investigated: Is it is possible achieve and accurate segmentation of trees? Are young trees going to pose a problem (shall they be included or excluded)? Do different training shapes (number of polygons and their size) influence the selection process of *'Forward Feature Selection'* with `IKARUS::BestPredFFS` and how? Does the number, shape and size of polygons of training shapes influence the result of the *'Classification'* - if yes how? Do different spectral raster stacks influence the choice of *'Forward Feature Selection'* with `IKARUS::BestPredFFS` in preparation for the *'Classification'* and how? Valuable information to these question will be outlined in **Chapter 4 - Results** and the questions will be answered in **Chapter 5 - Discussion**.

